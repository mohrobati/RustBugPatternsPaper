In this work, through Ruxanne we successfully mined 20 cross project bug fix patterns. We introduced these patterns in two groups: 12 general patterns and 8 BC-related patterns. Clippy is able to detect four of the BC-related patterns. To the best of our knowledge, the rest of the patterns cannot be reported by the current linting tools. That is why, we believe our work introduces a new direction for IDE tools to help Rust developers.

In each group, we categorized the bug fix patterns based on the underlying program element. The patterns encompass a wide variety of program elements both in the general and BC-related patterns. This shows that our weighting scheme is acceptably unbiased. Also, the introduced patterns are all cross-project fix patterns. Each fix pattern has been seen at least in three different projects, indicating its commonality.

Furthermore, we expected to obtain certain patterns regarding some certain Rust related features, such as \verb+move+, but our results did not include those patterns. Our speculation is that, since Rust has a strong compiler check before creating the program executable, the programmers usually get many errors, and they only push their code once it is free of compile errors. That is why, we think there are some patterns that were hidden from our sight.

We believe our results can help researchers to create Rust tools for repair, fault localization, IDE linters, and etc. Also, these results can help program embedding methods to focus on more important aspects of a program and shrink down information more effectively.

\subsection{Threats to Validity}

In our work there are three main threats to internal validity: (1) We use a weighting scheme which is based on a heuristic to give more values to tree elements closer to the leaves. In addition to that, we also manually adjusted the weights of borrow checker related elements to respect ownership framework's role in Rust, though we recorded their results separate from general results. As this approach is based on an intuition, it does not guarantee achieving optimal clusters. (2) The collected commits are the ones that fix a bug in a previously pushed commit. We do not consider the bugs that occur during a commit and also fixed during the same commit. (3) Our data modelling approach is based on the frequency of observed program elements in ASTs, and we use DBSCAN as our clustering algorithm. Other program data modelling methods and clustering algorithms (e.g.SLINK) might output new clusters that our pipeline is unable to find. 

The threat to external validity can be the developers reporting the commits as bug fixing commits while they are not really fixing a functionality. Similarly, a commit message might not contain our target keywords while the commit is associated with bug fixing changes.
