Automated program repair aims to debug faulty source code without human involvement, sometimes using test cases to guide the repair. Before a repair tool modifies code, it will typically use a fault localization module to find fault locations. A fault localization module ranks program statements based on suspiciousness; one example is Tarantula by \cite{jones2005empirical}. Suspiciousness is calculated using a statistical model which relies on the observation that buggy statements are executed mostly by failed test cases~\citep{naish2009spectral,xie2013theoretical}.

Researchers have proposed different methods for code repair, each of which can be said to follow a different mindset. Following the taxonomy propsed by \cite{liu2018survey}, we briefly present two mindsets, and will discuss how having a set of predefined fix patterns can aid repair.

\subsection{Search-Based Program Repair}
One line of research in program repair follows the competent programmer hypothesis~\citep{gopinath2014mutant}: syntactically, a faulty program is not that far away from its correct version. This hypothesis suggests the search-based program repair mindset. If the hypothesis holds, we can develop mutation operators (which change an expression or a statement) and apply them to a list of fault locations provided by the fault localization module. So, we loop through possible mutations; if the mutation of a statement does not cause all expected-successful test cases to succeed, we assume that the statement is correct and move on to the next fault location. Having a set of bug-producing patterns, like the ones we are proposing, will help researchers design targetted mutation operators that leverage domain specific insights.

Use of mutation operators in program repair became popular when \cite{forrest2009genetic} and \cite{nguyen2009using} developed GenProg, a program repair tool that uses genetic programming. The main idea behind this tool is that statements follow certain patterns in a codebase. Therefore, if we find the correct version of a faulty statement somewhere in the program, we can use that version in place of the faulty original. This tool showed promising results as it managed to find patches without any additional annotations or human involvements.

However, \cite{arcuri2011practical} observed that GenProg mostly found the patch while carrying out random initialization---that is, before GenProg's evolution begins. Their tools TrpAutoRepair~\citep{qi2013efficient} and RSRepair~\citep{qi2014strength} advocate that test case prioritization is necessary while using genetic programming, as fitness evaluation is an expensive part of the repair pipeline.

\cite{tan2015relifix} used mutation repairing for fixing regression bugs. They categorized common code changes in real-world regressions after studying 73 program evolution benchmarks; our approach also yields a set of common code changes, for Rust, using a different set of changes. Tan and Rovehoudhury used their categorization to design mutation operators, and drew from those operators to repair faulty program locations.

\subsection{Pattern-based Program Repair and Mining Bug Fix Patterns}

The main intuition in pattern-based program repair methods is that bug fixes follow certain patterns. Thus, having a collection of common bug fix patterns is a crucial step for developing such repair tools. \cite{pan2009toward} analyzed seven large-scale widely used Java projects and obtained 27 common bug fix patterns. They used a bug fix pattern extractor tool to automatically parse and detect bug patterns within the bug fix hunks with less than seven statements. They ignored larger bug fix hunks as they tended to exhibit random changes and did not have observable meaningful patterns. Though they did the analysis on Java projects, their reported patterns were not specific to Java. \cite{martinez2015mining,martinez2012mining} exploited the frequency of observed patterns to introduce a heuristic patch searching method. In their empirical evaluation, they concluded that choosing repair actions probabilistically (weighted by frequency) can help with reducing the search space, hence creating a more effective repair tool.

\cite{hanam2016discovering} conducted similar research, but for finding pervasive bug fix patterns in JavaScript. They performed a large-scale study of bug fix patterns by mining 105K commits from 134 server-side JavaScript projects. Like us, they used the DBSCAN clustering algorithm and divided bug fixing change types into 219 clusters, from which they extracted 13 pervasive cross-project bug fix patterns. 

\cite{yang2022mining} proposed a mining approach to detect Python bug fix patterns by studying fine-grained fixing code changes. They also examined how many bugs could be fixed using automated bug fixing approaches. Moreover, they evaluated the fix patterns that they detected and concluded that 37\% of the buggy codes could be matched by the fix patterns they had found. 

We would characterize our work as the Rust version of what was done in~\cite{hanam2016discovering} and~\cite{yang2022mining}. Like~\cite{hanam2016discovering}, we used DBSCAN to cluster fixes. Moreover, similar to~\cite{yang2022mining}, we introduced patterns in two different categories. In our case there were general and language-specific patterns; for Rust, the language-specific patterns were related to the borrow checker (BC patterns). However, unlike our paper, \cite{yang2022mining} needed to do a much more elaborate manual analysis, as they had only collected general information about the single hunk changes (e.g. the number of variables, or arguments).

\subsection{Code Embedding}

Recent advances in deep learning has motivated researchers to build models for various types of data. A common step for building these machine learning models is to create a numerical representation of data, so that it can be fed into the model. To realize this mapping in natural languages, the researchers have proposed methods to embed word information in fixed size vectors. This process is known as word embedding. As programming languages are not that different from natural languages~\citep{hindle2016naturalness}, similar mappings have been suggested for computer programs~\citep{chen2019literature}.

\cite{alon2019code2vec} presented code2vec, a nueral model for representing code snippets as fixed size vectors. In their approach, they extracted flattened paths from the AST, and stored all the leaf-to-leaf paths. The intuition behind this decision was that leaf-to-leaf paths tend to encode more semantic information than root-to-leaf paths. They associated a fixed size vector to each path and fed them as inputs to a neural network that learns how to aggregate all these paths to a single embedding. Our code embedding approach is simpler than code2vec, as we seek a less sophisticated goal than them---bug patterns clustering instead of method name prediction. Moreover, unlike us, code2vec does not offer a general code embedding methods, since the final embedding depends on the output layer of the neural network. That is, if we change the goal of method name prediction, the embeddings would be completely different. Also, our code embedding has actual interpretability as our columns are associated with non terminals. In code2vec, the dimensions of the final vector is a parameter of the system and to no extent is related to the underlying programming language.

Our work tends to be more similar to that of \cite{hanam2016discovering}. However, our novel program embedding approach might differ from what they did on certain key decisions. In~\cite{hanam2016discovering}, they introduced the Feature Properties table, which is a categorization for program elements. Embedding programs based on this table resulted in an order-sensitive embedding, however, it made the datapoints sparse.

\subsection{Code Patterns in Rust}

To our knowledge, our work is the first to use an automated mining and code analysis pipeline to find pervasive patterns in Rust open source projects, even if previous studies have investigated common bug patterns in Rust.

\cite{qin2020understanding} conducted the first empirical study on real-world Rust program behaviours. They manually inspected 850 unsafe code usages and 17 bugs across five open-source Rust projects, five Rust libraries, two online security databases, and the Rust standard library. They analyzed the motivation behind unsafe code usage and removal, in addition to recording 70 memory-safety issues and 100 concurrency bugs. They also provided Rust programmers with some suggestions and insights to develop better Rust programs. Using the results of their manual analysis, they designed two bug detectors, and provided recommendations for developing more bug detectors in the future.

\cite{li2021mirchecker} present MirChecker, a fully automated bug detection framework for Rust. This framework works by carrying out static analysis on Rust's Mid-level Intermediate Representation (MIR). The tool exploits the insights obtained from observing existing bugs (by studying reported CVEs) in Rust code bases. Using both numerical (e.g. integer bounds) and symbolic (e.g. modelling memory) information, the framework detects errors by using constraint solving techniques. MirChecker detected 33 new bugs, including 16 memory safety faults, across 12 Rust crates.

